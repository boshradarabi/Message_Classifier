{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWw0qlo9L+M4kAHfRlC5kA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boshradarabi/Message_Classifier/blob/main/Task2_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Connect to Drive**"
      ],
      "metadata": {
        "id": "MXVYV1uRh4NM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpH7nWguN05s",
        "outputId": "597d59e8-0d52-4db4-d131-06cb9006709e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2. Build Dataset**"
      ],
      "metadata": {
        "id": "AxpbE0kJiBFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "class DatasetBuilder:\n",
        "    def __init__(self):\n",
        "        self.urgent_keywords = [\n",
        "            'urgent', 'asap', 'emergency', 'immediately', 'critical','important', 'deadline', 'alert',\n",
        "            'warning', 'attention', 'breaking', 'now', 'quick', 'hurry', 'rush'\n",
        "        ]\n",
        "\n",
        "        self.negative_urgent_patterns = [\n",
        "            r'\\bnot urgent\\b',\n",
        "            r\"\\bit'?s not urgent\\b\",\n",
        "            r\"don't worry\\b\",\n",
        "            r\"\\bno emergency\\b\",\n",
        "            r\"\\bnot critical\\b\"\n",
        "        ]\n",
        "\n",
        "        self.real_urgent = [\n",
        "            \"URGENT: Server down! Please check immediately!\",\n",
        "            \"EMERGENCY: Critical security breach detected!\",\n",
        "            \"ASAP: Need your approval on the contract today!\",\n",
        "            \"IMPORTANT: Deadline extended to 5 PM today\",\n",
        "            \"CRITICAL: Payment failed, account will be suspended\",\n",
        "            \"ATTENTION: Meeting rescheduled to NOW\",\n",
        "            \"WARNING: System will shut down in 10 minutes\",\n",
        "            \"Call me immediately, it's urgent\",\n",
        "            \"ALERT: Suspicious activity on your account\",\n",
        "            \"Urgent: Boss wants to see you right now\",\n",
        "            \"WARNING: Hard drive failure predicted\",\n",
        "            \"CRITICAL: SMS service offline\",\n",
        "            \"Emergency: Fire alarm triggered in hallway\",\n",
        "            \"ATTENTION: VPN connection unstable\",\n",
        "            \"Important: Last chance to submit request\",\n",
        "            \"Urgent: Need replacement part today\",\n",
        "            \"ASAP open Teams the meeting started\",\n",
        "            \"WARNING: Multiple login attempts blocked\",\n",
        "            \"Emergency: Elevator stuck with people inside\",\n",
        "            \"Critical: Network latency extremely high\",\n",
        "            \"URGENT: Answer your email immediately\",\n",
        "            \"ALERT: Suspicious transaction flagged\",\n",
        "            \"ASAP bring the documents with you\",\n",
        "            \"Important: Customer waiting at front desk\"\n",
        "        ]\n",
        "\n",
        "\n",
        "    def create_urgent_messages(self, df, n_samples=500):\n",
        "        urgent_messages = []\n",
        "        ham_messages = df[df['label'] == 'ham']['message'].values\n",
        "\n",
        "        # strategy 1: urgent keywords with ham\n",
        "        for msg in ham_messages:\n",
        "            if any(kw in msg.lower() for kw in self.urgent_keywords):\n",
        "                urgent_messages.append(msg)\n",
        "                if len(urgent_messages) >= n_samples // 3:\n",
        "                    break\n",
        "\n",
        "        # strategy 2: Augmentation\n",
        "        prefixes = ['URGENT: ', 'EMERGENCY: ', 'ASAP: ', 'IMPORTANT: ', 'CRITICAL: ', 'ATTENTION: ', 'WARNING: ', 'ALERT: ']\n",
        "\n",
        "        np.random.seed(42)\n",
        "        random_hams = np.random.choice(ham_messages, size=n_samples // 3, replace=False)\n",
        "        for msg in random_hams:\n",
        "            prefix = np.random.choice(prefixes)\n",
        "            urgent_messages.append(prefix + msg)\n",
        "\n",
        "        # strategy 3: custom messages\n",
        "        remaining = n_samples - len(urgent_messages)\n",
        "        urgent_messages.extend(self.real_urgent * (remaining // len(self.real_urgent) + 1))\n",
        "        urgent_messages = urgent_messages[:n_samples]\n",
        "\n",
        "        return pd.DataFrame({'label': ['urgent'] * len(urgent_messages), 'message': urgent_messages})\n",
        "\n",
        "\n",
        "    def load_data(self, csv_path):\n",
        "        df = pd.read_csv(csv_path, encoding='latin-1')\n",
        "        df = df[['v1', 'v2']]\n",
        "        df.columns = ['label', 'message']\n",
        "\n",
        "        urgent_df = self.create_urgent_messages(df, n_samples=500)\n",
        "        df = pd.concat([df, urgent_df], ignore_index=True)\n",
        "        df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "        df['label'] = df['label'].replace({'ham': 'normal'})\n",
        "\n",
        "        stats = {\n",
        "            'total': len(df),\n",
        "            'urgent': len(df[df['label'] == 'urgent']),\n",
        "            'normal': len(df[df['label'] == 'normal']),\n",
        "            'spam': len(df[df['label'] == 'spam'])\n",
        "        }\n",
        "\n",
        "        print(\"â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
        "        print(f\"\\nğŸ“Š Dataset Information: {stats}\")\n",
        "\n",
        "        return df, stats"
      ],
      "metadata": {
        "id": "b1Gviy5RPjtA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**3. Message Classifier**"
      ],
      "metadata": {
        "id": "-MbdU5FgiXtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1. Import Dependencies:**"
      ],
      "metadata": {
        "id": "_ZCd907Ein9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import re\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import difflib\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "uxoPcb5EN4yG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2. preprocess and train model:**"
      ],
      "metadata": {
        "id": "n54RXB29iwZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MessageClassifier:\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            max_features=2000,\n",
        "            ngram_range=(1, 2),\n",
        "            min_df=2,\n",
        "            max_df=0.8,\n",
        "            strip_accents='unicode',\n",
        "            lowercase=True,\n",
        "            stop_words='english'\n",
        "        )\n",
        "\n",
        "        self.models = {\n",
        "            'naive_bayes': MultinomialNB(alpha=0.1),\n",
        "            'logistic': LogisticRegression(max_iter=1000, C=1.0, random_state=42),\n",
        "            'random_forest': RandomForestClassifier(n_estimators=100, max_depth=20, random_state=42),\n",
        "            'neural_network': MLPClassifier(\n",
        "                hidden_layer_sizes=(100),\n",
        "                activation='relu',\n",
        "                solver='adam',\n",
        "                max_iter=30,\n",
        "                random_state=42\n",
        "            )\n",
        "        }\n",
        "\n",
        "        self.best_model = None\n",
        "        self.best_model_name = None\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        text = str(text).lower()\n",
        "        text = re.sub(r'http\\S+|www\\S+', 'urllink', text)\n",
        "        text = re.sub(r'\\S+@\\S+', 'emailaddr', text)\n",
        "        text = re.sub(r'\\d{10}|\\d{3}[-.\\s]?\\d{3}[-.\\s]?\\d{4}', 'phonenumber', text)\n",
        "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return text\n",
        "\n",
        "    def is_similar(self, word, keywords, threshold=0.85):\n",
        "        # returns True, for high similarity to keywords\n",
        "        for kw in keywords:\n",
        "            ratio = difflib.SequenceMatcher(None, word, kw).ratio()\n",
        "            if ratio >= threshold:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def rule_based_check(self, message):\n",
        "        msg = message.lower()\n",
        "        tokens = msg.split()\n",
        "\n",
        "        negative_keywords = [\n",
        "            \"not urgent\", \"not important\", \"not critical\",\n",
        "            \"don't worry\", \"no emergency\"\n",
        "        ]\n",
        "\n",
        "        positive_keywords = [\n",
        "            \"urgent\", \"asap\", \"important\", \"critical\",\n",
        "            \"immediately\", \"attention\", \"warning\", \"alert\", \"emergency\"\n",
        "        ]\n",
        "\n",
        "        # 1) check negative keywords\n",
        "        for neg in negative_keywords:\n",
        "            if neg in msg:\n",
        "                return \"normal\"\n",
        "\n",
        "        # 2) Check positive cases with typo detection\n",
        "        for token in tokens:\n",
        "            if self.is_similar(token, positive_keywords):\n",
        "                return \"urgent\"\n",
        "\n",
        "        return None\n",
        "\n",
        "    def train(self, df):\n",
        "        df['processed'] = df['message'].apply(self.preprocess_text)\n",
        "\n",
        "        X = self.vectorizer.fit_transform(df['processed'])\n",
        "        y = df['label']\n",
        "\n",
        "        # split dataset\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        print(f\"ğŸ“Š Train: {X_train.shape[0]:,}, Test: {X_test.shape[0]:,}\")\n",
        "        print(\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
        "\n",
        "        # train models\n",
        "        results = {}\n",
        "        print(\"ğŸ¯ Training Models:\")\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            print(f\"\\nâ–¸ {name.title()}: \")\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            acc = accuracy_score(y_test, y_pred)\n",
        "            cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "\n",
        "            results[name] = {\n",
        "                'model': model,\n",
        "                'accuracy': acc,\n",
        "                'cv_mean': cv_scores.mean(),\n",
        "                'cv_std': cv_scores.std(),\n",
        "                'predictions': y_pred,\n",
        "                'y_test': y_test\n",
        "            }\n",
        "\n",
        "            print(f\"âœ“ Accuracy: {acc*100:.2f}% | CV: {cv_scores.mean()*100:.2f}% (Â±{cv_scores.std()*100:.2f}%)\")\n",
        "        print(\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
        "\n",
        "        # choose the best\n",
        "        best_name = max(results, key=lambda x: results[x]['accuracy'])\n",
        "        self.best_model = results[best_name]['model']\n",
        "        self.best_model_name = best_name\n",
        "\n",
        "        print(f\"ğŸ† Best Model: {best_name.replace('_', ' ').title()}\")\n",
        "        print(f\"   â€¢ Accuracy: {results[best_name]['accuracy']*100:.2f}%\")\n",
        "        print(f\"   â€¢ CV Score: {results[best_name]['cv_mean']*100:.2f}%\")\n",
        "        print(\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
        "\n",
        "        return results, X_test, y_test, self.best_model_name\n",
        "\n",
        "\n",
        "    def predict(self, message):\n",
        "        rule_label = self.rule_based_check(message)\n",
        "        if rule_label is not None:\n",
        "            return rule_label, 1.0, {rule_label: 1.0}\n",
        "\n",
        "        # predict a message\n",
        "        processed = self.preprocess_text(message)\n",
        "        X = self.vectorizer.transform([processed])\n",
        "        prediction = self.best_model.predict(X)[0]\n",
        "\n",
        "        if hasattr(self.best_model, 'predict_proba'):\n",
        "            proba = self.best_model.predict_proba(X)[0]\n",
        "            confidence = max(proba)\n",
        "            classes = self.best_model.classes_\n",
        "            proba_dict = {classes[i]: proba[i] for i in range(len(classes))}\n",
        "        else:\n",
        "            confidence = 1.0\n",
        "            proba_dict = {prediction: 1.0}\n",
        "\n",
        "        return prediction, confidence, proba_dict\n",
        "\n",
        "    def predict_batch(self, messages):\n",
        "        # predict batch\n",
        "        results = []\n",
        "        for msg in messages:\n",
        "            label, conf, proba = self.predict(msg)\n",
        "            results.append({\n",
        "                'message': msg[:70] + '...' if len(msg) > 70 else msg,\n",
        "                'predicted': label,\n",
        "                'confidence': f\"{conf*100:.1f}%\",\n",
        "                'prob_normal': f\"{proba.get('normal', 0)*100:.1f}%\",\n",
        "                'prob_spam': f\"{proba.get('spam', 0)*100:.1f}%\",\n",
        "                'prob_urgent': f\"{proba.get('urgent', 0)*100:.1f}%\"\n",
        "            })\n",
        "        return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "9Y_ZZgMURZTE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3. classification report & confution matrix method**"
      ],
      "metadata": {
        "id": "II4SfNZx-4dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_detailed_report(results, X_test, y_test, best_model_name):\n",
        "    best_name = best_model_name\n",
        "    y_pred = results[best_name]['predictions']\n",
        "\n",
        "    print(f\"ğŸ“ˆ classification report ({best_name.replace('_', ' ').title()})\")\n",
        "\n",
        "    print(\"\\n\" + classification_report(y_test, y_pred,\n",
        "                                        target_names=['normal', 'spam', 'urgent'],\n",
        "                                        digits=3))\n",
        "\n",
        "    print(\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=['normal', 'spam', 'urgent'])\n",
        "\n",
        "    print(\"ğŸ“Š Confusion Matrix:\")\n",
        "    print(\"                    Predicted\")\n",
        "    print(\"              Normal    Spam    Urgent\")\n",
        "    print(f\"    Normal     {cm[0,0]:5d}   {cm[0,1]:5d}    {cm[0,2]:5d}\")\n",
        "    print(f\"    Spam       {cm[1,0]:5d}   {cm[1,1]:5d}    {cm[1,2]:5d}\")\n",
        "    print(f\"    Urgent     {cm[2,0]:5d}   {cm[2,1]:5d}    {cm[2,2]:5d}\")\n",
        "\n",
        "    print(\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")"
      ],
      "metadata": {
        "id": "6zEpm5Nm-1QP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4. Test**"
      ],
      "metadata": {
        "id": "PuzfDmWJj8xG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1. Training Process:**"
      ],
      "metadata": {
        "id": "prBafmpEo5hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "csv_path = \"/content/drive/MyDrive/Task2/spam.csv\"     # SMS Spam Collection from Kaggle (ham / spam)\n",
        "\n",
        "dataset = DatasetBuilder()\n",
        "df, stats = dataset.load_data(csv_path)\n",
        "classifier = MessageClassifier()\n",
        "results, X_test, y_test, best_model_name = classifier.train(df)\n",
        "show_detailed_report(results, X_test, y_test, best_model_name)\n",
        "\n",
        "print(\"ğŸğŸğŸğŸğŸğŸTraining Process is Compeletly Done!ğŸğŸğŸğŸğŸğŸ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2-bD_TjeDq-",
        "outputId": "4d782fac-c09f-4598-d6ee-f1cb3a51b525"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "ğŸ“Š Dataset Information: {'total': 6072, 'urgent': 500, 'normal': 4825, 'spam': 747}\n",
            "ğŸ“Š Train: 4,857, Test: 1,215\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "ğŸ¯ Training Models:\n",
            "\n",
            "â–¸ Naive_Bayes: \n",
            "âœ“ Accuracy: 93.83% | CV: 93.27% (Â±0.35%)\n",
            "\n",
            "â–¸ Logistic: \n",
            "âœ“ Accuracy: 93.58% | CV: 93.06% (Â±0.45%)\n",
            "\n",
            "â–¸ Random_Forest: \n",
            "âœ“ Accuracy: 89.30% | CV: 88.63% (Â±0.77%)\n",
            "\n",
            "â–¸ Neural_Network: \n",
            "âœ“ Accuracy: 93.17% | CV: 92.63% (Â±0.26%)\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "ğŸ† Best Model: Naive Bayes\n",
            "   â€¢ Accuracy: 93.83%\n",
            "   â€¢ CV Score: 93.27%\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "ğŸ“ˆ classification report (Naive Bayes)\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      normal      0.933     0.994     0.962       966\n",
            "        spam      0.959     0.946     0.953       149\n",
            "      urgent      1.000     0.390     0.561       100\n",
            "\n",
            "    accuracy                          0.938      1215\n",
            "   macro avg      0.964     0.777     0.825      1215\n",
            "weighted avg      0.942     0.938     0.928      1215\n",
            "\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "ğŸ“Š Confusion Matrix:\n",
            "                    Predicted\n",
            "              Normal    Spam    Urgent\n",
            "    Normal       960       6        0\n",
            "    Spam           8     141        0\n",
            "    Urgent        61       0       39\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "ğŸğŸğŸğŸğŸğŸTraining Process is Compeletly Done!ğŸğŸğŸğŸğŸğŸ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2. Test some scenatios:**"
      ],
      "metadata": {
        "id": "QrAC-30jpC85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_scenarios = {\n",
        "    \"Normal Messages\": [\n",
        "        \"Hey, can we meet for coffee tomorrow at 3pm?\",\n",
        "        \"Thanks for sending the report. Looks good!\",\n",
        "        \"Happy birthday! Hope you have a wonderful day\",\n",
        "        \"Dinner tonight? Let me know if you're free\",\n",
        "        \"The presentation went really well today\"\n",
        "    ],\n",
        "\n",
        "    \"Spam Messages\": [\n",
        "        \"FREE! Win iPhone 15 Pro! Click now: www.scam.com\",\n",
        "        \"Congratulations! You won $1,000,000! Text YES to claim prize\",\n",
        "        \"Hot singles in your area want to meet you! Join now!\",\n",
        "        \"Limited time offer! 90% discount on all products! Buy now!\",\n",
        "        \"You have been selected for a free cruise! Call 555-1234\"\n",
        "    ],\n",
        "\n",
        "    \"Urgent Messages\": [\n",
        "        \"URGENT: Server is down! Please check immediately!\",\n",
        "        \"EMERGENCY: Critical security breach detected in system\",\n",
        "        \"ASAP: Boss needs the presentation in 10 minutes\",\n",
        "        \"CRITICAL: Production bug affecting all users\",\n",
        "        \"ATTENTION: Meeting moved to now, please join\"\n",
        "    ],\n",
        "\n",
        "    \"Challenging Cases\": [\n",
        "        \"LOL just kidding! But seriously we need to meet asap ğŸ˜‚\",\n",
        "        \"Important discount! Limited time offer! Buy now or never!\",\n",
        "        \"Please review the urgent matter we discussed yesterday\",\n",
        "        \"OMG you won't believe this amazing deal I found!\",\n",
        "        \"Can you PLEASE respond ASAP? It's about the project\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "print(\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n",
        "for category, messages in test_scenarios.items():\n",
        "    print(f\"âœ…âœ…âœ… {category} âœ…âœ…âœ…\")\n",
        "\n",
        "    predictions = classifier.predict_batch(messages)\n",
        "\n",
        "    for idx, row in predictions.iterrows():\n",
        "        print(f\"\\n  message: {row['message']}\")\n",
        "        print(f\"           prediction: {row['predicted'].upper()} ({row['confidence']})\")\n",
        "        print(f\"           probabilities: Normal={row['prob_normal']} | Spam={row['prob_spam']} | Urgent={row['prob_urgent']}\")\n",
        "\n",
        "    print(\"\\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfEhwdzqltWc",
        "outputId": "d010923c-70aa-4b3c-9073-9e13599cec6d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "âœ…âœ…âœ… Normal Messages âœ…âœ…âœ…\n",
            "\n",
            "  message: Hey, can we meet for coffee tomorrow at 3pm?\n",
            "           prediction: NORMAL (99.3%)\n",
            "           probabilities: Normal=99.3% | Spam=0.4% | Urgent=0.3%\n",
            "\n",
            "  message: Thanks for sending the report. Looks good!\n",
            "           prediction: NORMAL (98.6%)\n",
            "           probabilities: Normal=98.6% | Spam=0.8% | Urgent=0.6%\n",
            "\n",
            "  message: Happy birthday! Hope you have a wonderful day\n",
            "           prediction: NORMAL (96.7%)\n",
            "           probabilities: Normal=96.7% | Spam=0.1% | Urgent=3.3%\n",
            "\n",
            "  message: Dinner tonight? Let me know if you're free\n",
            "           prediction: NORMAL (96.4%)\n",
            "           probabilities: Normal=96.4% | Spam=0.1% | Urgent=3.5%\n",
            "\n",
            "  message: The presentation went really well today\n",
            "           prediction: NORMAL (97.8%)\n",
            "           probabilities: Normal=97.8% | Spam=0.1% | Urgent=2.1%\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "âœ…âœ…âœ… Spam Messages âœ…âœ…âœ…\n",
            "\n",
            "  message: FREE! Win iPhone 15 Pro! Click now: www.scam.com\n",
            "           prediction: SPAM (98.0%)\n",
            "           probabilities: Normal=1.8% | Spam=98.0% | Urgent=0.1%\n",
            "\n",
            "  message: Congratulations! You won $1,000,000! Text YES to claim prize\n",
            "           prediction: SPAM (100.0%)\n",
            "           probabilities: Normal=0.0% | Spam=100.0% | Urgent=0.0%\n",
            "\n",
            "  message: Hot singles in your area want to meet you! Join now!\n",
            "           prediction: NORMAL (69.2%)\n",
            "           probabilities: Normal=69.2% | Spam=29.0% | Urgent=1.8%\n",
            "\n",
            "  message: Limited time offer! 90% discount on all products! Buy now!\n",
            "           prediction: NORMAL (75.8%)\n",
            "           probabilities: Normal=75.8% | Spam=23.5% | Urgent=0.6%\n",
            "\n",
            "  message: You have been selected for a free cruise! Call 555-1234\n",
            "           prediction: SPAM (70.3%)\n",
            "           probabilities: Normal=28.5% | Spam=70.3% | Urgent=1.3%\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "âœ…âœ…âœ… Urgent Messages âœ…âœ…âœ…\n",
            "\n",
            "  message: URGENT: Server is down! Please check immediately!\n",
            "           prediction: URGENT (100.0%)\n",
            "           probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "  message: EMERGENCY: Critical security breach detected in system\n",
            "           prediction: URGENT (100.0%)\n",
            "           probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "  message: ASAP: Boss needs the presentation in 10 minutes\n",
            "           prediction: URGENT (100.0%)\n",
            "           probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "  message: CRITICAL: Production bug affecting all users\n",
            "           prediction: URGENT (100.0%)\n",
            "           probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "  message: ATTENTION: Meeting moved to now, please join\n",
            "           prediction: URGENT (100.0%)\n",
            "           probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n",
            "âœ…âœ…âœ… Challenging Cases âœ…âœ…âœ…\n",
            "\n",
            "  message: LOL just kidding! But seriously we need to meet asap ğŸ˜‚\n",
            "           prediction: URGENT (100.0%)\n",
            "           probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "  message: Important discount! Limited time offer! Buy now or never!\n",
            "           prediction: URGENT (100.0%)\n",
            "           probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "  message: Please review the urgent matter we discussed yesterday\n",
            "           prediction: URGENT (100.0%)\n",
            "           probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "  message: OMG you won't believe this amazing deal I found!\n",
            "           prediction: NORMAL (94.2%)\n",
            "           probabilities: Normal=94.2% | Spam=5.0% | Urgent=0.7%\n",
            "\n",
            "  message: Can you PLEASE respond ASAP? It's about the project\n",
            "           prediction: URGENT (100.0%)\n",
            "           probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3. Test custom messages**"
      ],
      "metadata": {
        "id": "HGMn0FX8pTG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_custom_message(message):\n",
        "    predictions = classifier.predict_batch([message])\n",
        "    row = predictions.iloc[0]\n",
        "\n",
        "    print(f\"\\nmessage: {message}\")\n",
        "    print(f\"         prediction: {row['predicted'].upper()} ({row['confidence']})\")\n",
        "    print(f\"         probabilities: Normal={row['prob_normal']} | Spam={row['prob_spam']} | Urgent={row['prob_urgent']}\")\n",
        "\n",
        "\n",
        "\n",
        "sample_messages = [\n",
        "    \"Can we reschedule our meeting to next week?\",\n",
        "    \"FREE iPhone giveaway! Click here now!!!\",\n",
        "    \"URGENT: Critical bug in production needs immediate fix\",\n",
        "    \"Thanks for your help yesterday, really appreciate it\",\n",
        "    \"it's not urgent. sleep.\",\n",
        "    \"click here to buy new collection\",\n",
        "    \"call me asalp\",\n",
        "    \"Server is down! Please check immediately!\"\n",
        "]\n",
        "\n",
        "for msg in sample_messages:\n",
        "    test_custom_message(msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrxPVZ_wpaLB",
        "outputId": "ba1185fc-ed78-4599-efa4-d46088d6da72"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "message: Can we reschedule our meeting to next week?\n",
            "         prediction: NORMAL (87.4%)\n",
            "         probabilities: Normal=87.4% | Spam=1.2% | Urgent=11.4%\n",
            "\n",
            "message: FREE iPhone giveaway! Click here now!!!\n",
            "         prediction: SPAM (74.2%)\n",
            "         probabilities: Normal=23.0% | Spam=74.2% | Urgent=2.9%\n",
            "\n",
            "message: URGENT: Critical bug in production needs immediate fix\n",
            "         prediction: URGENT (100.0%)\n",
            "         probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "message: Thanks for your help yesterday, really appreciate it\n",
            "         prediction: NORMAL (98.7%)\n",
            "         probabilities: Normal=98.7% | Spam=0.4% | Urgent=0.9%\n",
            "\n",
            "message: it's not urgent. sleep.\n",
            "         prediction: NORMAL (100.0%)\n",
            "         probabilities: Normal=100.0% | Spam=0.0% | Urgent=0.0%\n",
            "\n",
            "message: click here to buy new collection\n",
            "         prediction: SPAM (87.5%)\n",
            "         probabilities: Normal=10.9% | Spam=87.5% | Urgent=1.6%\n",
            "\n",
            "message: call me asalp\n",
            "         prediction: URGENT (100.0%)\n",
            "         probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n",
            "\n",
            "message: Server is down! Please check immediately!\n",
            "         prediction: URGENT (100.0%)\n",
            "         probabilities: Normal=0.0% | Spam=0.0% | Urgent=100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-IoPHitcCwG1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}